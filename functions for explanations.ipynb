{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import utils\n",
    "import anchor_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "moons_anchor = pickle.load(open('out_pickles/moons-anchor-svm', 'rb'))#, encoding='latin1')\n",
    "moons_lime = pickle.load(open('out_pickles/moons-lime-svm', 'rb'))#, encoding='latin1')\n",
    "\n",
    "X, y = make_moons(noise=0.3, random_state=0)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "    #X[:, 0] *= 10\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.4, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=2, kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moons_lime['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset (already discretized)\n",
    "dataset = utils.load_dataset('moons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = moons_lime['exps']\n",
    "data_exps = dataset.data[moons_lime['validation_idx']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x1', 'x2']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 1.],\n",
       "       [3., 1.],\n",
       "       [2., 0.],\n",
       "       [1., 1.],\n",
       "       [3., 2.],\n",
       "       [0., 3.],\n",
       "       [3., 2.],\n",
       "       [3., 1.],\n",
       "       [2., 3.],\n",
       "       [0., 2.],\n",
       "       [3., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 2.],\n",
       "       [3., 2.],\n",
       "       [3., 1.],\n",
       "       [3., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 2.],\n",
       "       [2., 0.],\n",
       "       [1., 2.],\n",
       "       [1., 1.],\n",
       "       [0., 3.],\n",
       "       [3., 2.],\n",
       "       [0., 3.],\n",
       "       [0., 2.],\n",
       "       [2., 0.],\n",
       "       [2., 3.],\n",
       "       [0., 2.],\n",
       "       [2., 2.],\n",
       "       [0., 2.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [2., 0.],\n",
       "       [1., 3.],\n",
       "       [2., 1.],\n",
       "       [1., 1.],\n",
       "       [2., 2.],\n",
       "       [1., 1.],\n",
       "       [3., 2.],\n",
       "       [2., 1.],\n",
       "       [0., 3.],\n",
       "       [1., 3.],\n",
       "       [0., 1.],\n",
       "       [0., 3.],\n",
       "       [2., 1.],\n",
       "       [1., 2.],\n",
       "       [2., 3.],\n",
       "       [1., 3.],\n",
       "       [3., 0.],\n",
       "       [0., 2.],\n",
       "       [2., 3.],\n",
       "       [0., 3.],\n",
       "       [1., 0.],\n",
       "       [2., 0.],\n",
       "       [1., 0.],\n",
       "       [3., 3.],\n",
       "       [2., 2.],\n",
       "       [1., 1.],\n",
       "       [1., 2.],\n",
       "       [3., 1.],\n",
       "       [3., 1.],\n",
       "       [3., 0.],\n",
       "       [0., 3.],\n",
       "       [0., 2.],\n",
       "       [3., 1.],\n",
       "       [0., 0.],\n",
       "       [2., 2.],\n",
       "       [0., 3.],\n",
       "       [1., 3.],\n",
       "       [3., 1.],\n",
       "       [1., 3.],\n",
       "       [2., 0.],\n",
       "       [3., 0.],\n",
       "       [3., 3.],\n",
       "       [1., 0.],\n",
       "       [3., 2.],\n",
       "       [0., 1.],\n",
       "       [3., 0.],\n",
       "       [1., 2.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import pickle\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#from sklearn.datasets import make_moons\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "import utils\n",
    "import anchor_tabular\n",
    "\n",
    "\n",
    "# Create the dataset discretized, and the split for test and training are all done inside here\n",
    "dataset = utils.load_dataset('moons')\n",
    "\n",
    "# Define the discretizer on the WHOLE data, not just train. It can be done by calling it from the dataset loaded.\n",
    "disc = dataset.disc\n",
    "\n",
    "# Define the explainer object that the anchor and lime will use\n",
    "explainer_obj = anchor_tabular.AnchorTabularExplainer(dataset.class_names, \\\n",
    "                                                          dataset.feature_names, \\\n",
    "                                                          dataset.data, \\\n",
    "                                                          dataset.categorical_names)\n",
    "explainer_obj.fit(dataset.train, dataset.labels_train, dataset.validation, dataset.labels_validation)\n",
    "\n",
    "\n",
    "def get_lime_explanation_fn(clf, x_0, disc, explainer_obj):\n",
    "    \"\"\"\n",
    "    Returns a function that takes in a data point (in the ORIGINAL space) that spits out the explanations\n",
    "    \n",
    "    params: clf the classifier we want to explain\n",
    "    params: x_0 the center point\n",
    "    params: disc the discretization method to use (can be the ones from lime API)\n",
    "    params: explainer object that is required for lime and anchor explanation\n",
    "    \n",
    "    output: a function that takes in a data point (in the ORIGINAL space) that spits out the explanations\n",
    "    \"\"\"\n",
    "   \n",
    "    x_0_disc = disc.discretize(x_0)\n",
    "    \n",
    "    explain_fn = utils.get_reduced_explain_fn(explainer_obj.explain_lime, clf.predict_proba, num_features=5, use_same_dist=True)\n",
    "    exp = explain_fn(x_0_disc)\n",
    "    intercept = exp['intercept']\n",
    "    \n",
    "    def g(x):\n",
    "        x_tilde = disc.discretize(x)\n",
    "        weights = []\n",
    "        for f in exp['as_map']:\n",
    "            weights.append(exp['as_map'][f])\n",
    "        scores = np.dot(x_tilde, np.array(weights)) + intercept\n",
    "        if scores > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    return g\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anchor_explanation_fn(f, x_center, disc, explainer_obj):\n",
    "    threshold = 0.95\n",
    "    tau = 0.1\n",
    "    delta = 0.05\n",
    "    epsilon_stop = 0.05\n",
    "    batch_size = 100\n",
    "    explain_fn = utils.get_reduced_explain_fn(\n",
    "        explainer_obj.explain_lucb_beam, f.predict, threshold=threshold,\n",
    "        delta=delta, tau=tau, batch_size=batch_size / 2,\n",
    "        sample_whole_instances=True,\n",
    "        beam_size=10, epsilon_stop=epsilon_stop)\n",
    "    x_center_tilde = disc.discretize(x_center)\n",
    "    g_tilde = explain_fn(x_center_tilde) #explain_fn = explain_lucb_beam - k=line 254 in anchor_tabular;#g_tilde = anchor_base.AnchorBaseBeam.anchor_beam = exp\n",
    "    explanations = [g_tilde]\n",
    "    #print x_center_tilde, x_center\n",
    "    explanations_data = [x_center_tilde]\n",
    "    x_center_tilde_onehot = explainer_obj.encoder.transform(x_center_tilde.reshape(-1,2))\n",
    "    explanation_preds = f.predict(x_center_tilde_onehot)\n",
    "    print g_tilde\n",
    "    \n",
    "    def g(x):\n",
    "        x_tilde = disc.discretize(x)\n",
    "        dataset = x_tilde\n",
    "   \n",
    "        covered = {}\n",
    "        for i, (exp, d) in enumerate(zip(explanations, explanations_data)):\n",
    "            fs = []\n",
    "            for f, p in zip(exp['feature'], exp['precision']):\n",
    "                fs.append(f)\n",
    "                if p >= threshold:\n",
    "                    break\n",
    "            fs = np.array(fs)\n",
    "            covered[i] = set(np.all(dataset[fs] == d[fs]).nonzero()[0])\n",
    "\n",
    "        votes = []\n",
    "        for j in covered:\n",
    "            if i in covered[j]:\n",
    "                votes.append(explanation_preds[j])\n",
    "        if votes:\n",
    "            print votes\n",
    "            return np.random.choice(votes)\n",
    "        else:\n",
    "            return None\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'names': ['x2 > 0.66', '-0.14 < x1 <= 0.47'], 'feature': [1, 0], 'precision': [0.8235294117647058, 1.0], 'num_preds': 500001, 'examples': [{'covered': array([[2., 3.],\n",
      "       [2., 3.],\n",
      "       [2., 3.],\n",
      "       [1., 3.],\n",
      "       [2., 3.],\n",
      "       [3., 3.],\n",
      "       [2., 3.],\n",
      "       [2., 3.],\n",
      "       [2., 3.],\n",
      "       [2., 3.]]), 'uncovered_true': array([], dtype=float64), 'covered_true': array([[0., 3.],\n",
      "       [1., 3.],\n",
      "       [1., 3.],\n",
      "       [2., 3.],\n",
      "       [1., 3.],\n",
      "       [2., 3.],\n",
      "       [1., 3.],\n",
      "       [1., 3.],\n",
      "       [2., 3.],\n",
      "       [2., 3.]]), 'uncovered_false': array([], dtype=float64), 'covered_false': array([[3., 3.],\n",
      "       [3., 3.],\n",
      "       [3., 3.],\n",
      "       [3., 3.],\n",
      "       [3., 3.],\n",
      "       [3., 3.],\n",
      "       [3., 3.],\n",
      "       [3., 3.],\n",
      "       [3., 3.]])}, {'covered': array([[1., 3.],\n",
      "       [1., 3.],\n",
      "       [1., 3.],\n",
      "       [1., 3.],\n",
      "       [1., 3.],\n",
      "       [1., 3.],\n",
      "       [1., 3.],\n",
      "       [1., 3.],\n",
      "       [1., 3.],\n",
      "       [1., 3.]]), 'uncovered_true': array([], dtype=float64), 'covered_true': array([[1., 3.],\n",
      "       [1., 3.],\n",
      "       [1., 3.],\n",
      "       [1., 3.],\n",
      "       [1., 3.],\n",
      "       [1., 3.],\n",
      "       [1., 3.],\n",
      "       [1., 3.],\n",
      "       [1., 3.],\n",
      "       [1., 3.]]), 'uncovered_false': array([], dtype=float64), 'covered_false': array([], shape=(0, 2), dtype=float64)}], 'coverage': [0.3022, 0.2024], 'all_precision': 0, 'mean': [0.8235294117647058, 1.0]}\n",
      "[0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnX1Lua+AAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8d39b13f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = moons_lime['model']\n",
    "clf = moons_anchor['model']\n",
    "x_0 = dataset.data[moons_lime['validation_idx'][2]]\n",
    "#g = get_lime_explanation_fn(clf, x_0, disc, explainer_obj)\n",
    "g = get_anchor_explanation_fn(clf, x_0, disc, explainer_obj)\n",
    "\n",
    "for i in moons_lime['test_idx']:\n",
    "    test_point = dataset.data[i]\n",
    "    plt.scatter(X[:,0], X[:,1], c=y)\n",
    "    plt.scatter(x_0[0], x_0[1], marker='x')\n",
    "    correct = g(test_point) == dataset.labels[i]\n",
    "    if correct:\n",
    "        plt.scatter(test_point[0], test_point[1], marker='*', c='b')\n",
    "    else:\n",
    "        plt.scatter(test_point[0], test_point[1], marker='*', c='r')\n",
    "        \n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
